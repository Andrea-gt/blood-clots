{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Classification of Blood Clot Origins in Ischemic Strokes ðŸ©¸**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the present project is classifying the etiology of blood clots in whole-slide digital pathology images, specifically identifying whether they are of Cardioembolic (CE) or Large Artery Atherosclerosis (LAA) origin. Previosly, through an extensive exploratory data analysis (EDA), we described the dataset, analyzed missing and duplicate values, examined the distribution of image sizes, classified variables, and reviewed the label distribution for the training set, along with plenty of other analysis. \n",
    "\n",
    "In the current notebook, we preprocess the images to standardize them for model input. The preprocessing involves resizing, converting images to RBG, normalizing pixel values, and discard images that are mainly background. These steps ensure that the images are suitable for the models by preparing them with a consistent size, format, and reduced noise, enabling more efficient training and improved classification accuracy.\n",
    "\n",
    "The image pre-processing detailed here serves primarily as a refined, second iteration, tailored specifically for the model in `model_notebooks/Modelo_EfficientNetwork.ipynb`. For a simpler, preliminary approach, refer to the initial EDA and preprocessing outlined in `model_notebooks/mayo.clinic.strip.ai.upynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors:**\n",
    "- [Daniel Valdez](https://github.com/Danval-003)\n",
    "- [Emilio Solano](https://github.com/emiliosolanoo21)\n",
    "- [Adrian Flores](https://github.com/adrianRFlores)\n",
    "- [Andrea RamÃ­rez](https://github.com/Andrea-gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **(1) Import Libraries** â¬‡ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Standard Libraries =====\n",
    "import os  # OS utilities\n",
    "import numpy as np  # Numerical computations\n",
    "import pandas as pd  # Data manipulation\n",
    "\n",
    "# ===== Image Processing =====\n",
    "import cv2  # OpenCV for image processing\n",
    "import openslide  # For handling digital pathology slide images\n",
    "\n",
    "# ===== Machine Learning =====\n",
    "from sklearn.model_selection import StratifiedKFold  # Stratified K-Folds cross-validator\n",
    "\n",
    "# ===== Multiprocessing =====\n",
    "from multiprocessing import Pool  # Parallel processing for improved performance\n",
    "\n",
    "# ===== Data Augmentation =====\n",
    "import albumentations as A  # Data augmentation library\n",
    "from albumentations.pytorch import ToTensorV2  # Converts images to PyTorch tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **(2) Second Iteration of Image Preprocessing ðŸ“·**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(1) Data Augmentation Techniques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define advanced augmentations to increase variability in data, particularly useful for minority classes\n",
    "minority_augmentations = A.Compose([\n",
    "    A.HorizontalFlip(p=0.8),  # Apply horizontal flip with 80% probability\n",
    "    A.VerticalFlip(p=0.8),  # Apply vertical flip with 80% probability\n",
    "    A.RandomRotate90(p=0.8),  # Randomly rotate image by 90 degrees with 80% probability\n",
    "    A.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2, p=0.8),  # Randomly adjust brightness, contrast, saturation, and hue with 80% probability\n",
    "    A.Perspective(p=0.5),  # Apply perspective transformation with 50% probability\n",
    "    A.RandomBrightnessContrast(p=0.6),  # Randomly adjust brightness and contrast with 60% probability\n",
    "    A.CoarseDropout(max_holes=10, max_height=20, max_width=20, min_holes=1, p=0.5),  # Randomly drop small rectangular regions in the image with 50% probability to introduce noise\n",
    "    A.Resize(256, 256),  # Resize image to 256x256 pixels\n",
    "    ToTensorV2()  # Convert image to PyTorch tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define augmentations for majority classes to introduce variability without excessive transformations\n",
    "majority_augmentations = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),  # Apply horizontal flip with 50% probability\n",
    "    A.VerticalFlip(p=0.5),  # Apply vertical flip with 50% probability\n",
    "    A.RandomRotate90(p=0.5),  # Randomly rotate image by 90 degrees with 50% probability\n",
    "    A.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2, p=0.5),  # Adjust brightness, contrast, saturation, and hue with 50% probability\n",
    "    A.Resize(256, 256),  # Resize image to 256x256 pixels\n",
    "    ToTensorV2()  # Convert image to PyTorch tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(2) Handling Patches With Mostly Background**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if an image patch is valid based on its grayscale intensity variation\n",
    "def is_valid_patch(img, threshold=15):\n",
    "    # Convert the image to grayscale for easier analysis of intensity variation\n",
    "    grayscale = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Calculate the standard deviation of pixel intensity in the grayscale image\n",
    "    # If the standard deviation meets or exceeds the threshold, the patch is considered valid\n",
    "    return np.std(grayscale) >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if an image patch is likely to be background based on intensity variation and color differences\n",
    "def is_background_patch(img, std_threshold=15, mean_diff_threshold=10):\n",
    "    # Convert the image to grayscale for analyzing intensity variation\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # If the standard deviation of the grayscale image is below the threshold, classify it as background\n",
    "    if np.std(gray) < std_threshold:\n",
    "        return True\n",
    "    # Calculate the mean color values for each channel (R, G, B)\n",
    "    mean_r, mean_g, mean_b = img[..., 0].mean(), img[..., 1].mean(), img[..., 2].mean()\n",
    "    # Check if the maximum difference between the mean color values is below the specified threshold\n",
    "    # If so, classify the patch as background (indicating little color variation)\n",
    "    return max(abs(mean_r - mean_g), abs(mean_r - mean_b), abs(mean_g - mean_b)) < mean_diff_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(3) Obtaining Image Patches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process image patches and apply balanced augmentations\n",
    "def preprocess_image(args):\n",
    "    image_path, label, idx, num_patches = args\n",
    "    print(f\"Processing image at index {idx}\")\n",
    "    \n",
    "    slide = openslide.OpenSlide(image_path)  # Open the image slide\n",
    "    width, height = slide.dimensions  # Get slide dimensions\n",
    "    patches = []  # Initialize list to store valid patches\n",
    "    \n",
    "    patch_size = 512  # Define the size of each patch\n",
    "    step_size = patch_size // 2  # Define the step size for patch extraction\n",
    "    max_attempts = num_patches * 30  # Maximum attempts to find valid patches\n",
    "    \n",
    "    attempts = 0  # Initialize attempt counter\n",
    "    for y in range(0, height - patch_size + 1, step_size):\n",
    "        for x in range(0, width - patch_size + 1, step_size):\n",
    "            if len(patches) >= num_patches:  # Stop if enough patches are collected\n",
    "                break\n",
    "            \n",
    "            img = slide.read_region((x, y), 0, (patch_size, patch_size)).convert(\"RGB\")  # Read the patch\n",
    "            img = np.array(img)  # Convert image to numpy array\n",
    "            \n",
    "            if is_background_patch(img):  # Check if the patch is likely background\n",
    "                continue\n",
    "            \n",
    "            if is_valid_patch(img):  # Check if the patch is valid\n",
    "                if label == 'LAA':  # Minority class\n",
    "                    augmented = minority_augmentations(image=img)  # Apply minority augmentations\n",
    "                    patches.extend([augmented['image']] * 2)  # Add duplicates\n",
    "                else:  # Majority class\n",
    "                    augmented = majority_augmentations(image=img)  # Apply majority augmentations\n",
    "                    patches.append(augmented['image'])  # Add the augmented image\n",
    "                \n",
    "                attempts = 0  # Reset attempts after successful patch extraction\n",
    "            else:\n",
    "                attempts += 1  # Increment attempts if patch is not valid\n",
    "            \n",
    "            if attempts >= max_attempts:  # Check if max attempts exceeded\n",
    "                print(f\"Maximum attempts exceeded for image {image_path}\")\n",
    "                break\n",
    "    \n",
    "    if len(patches) < num_patches:  # Check if sufficient valid patches were found\n",
    "        print(f\"Not enough valid patches found for the image at {image_path}\")\n",
    "        return None, None  # Return None if not enough patches were found\n",
    "    \n",
    "    patches_tensor = np.stack(patches[:num_patches], axis=0)  # Balance the final number of patches\n",
    "    return patches_tensor, label  # Return the tensor of patches and the label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(4) Saving Images Patches in Directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and save dataset in chunks\n",
    "def create_and_save_dataset_in_chunks(df, dataset_type, num_patches_per_image=15, chunk_size=5000):\n",
    "    # Define the directory for images based on the dataset type (train or test)\n",
    "    images_dir = '/kaggle/input/mayo-clinic-strip-ai/test' if dataset_type == 'test' else '/kaggle/input/mayo-clinic-strip-ai/train'\n",
    "    \n",
    "    all_images = []  # List to store all processed images\n",
    "    all_labels = []  # List to store labels (if not test dataset)\n",
    "    total_samples = 0  # Counter for total samples processed\n",
    "    chunk_index = 0  # Index for the current chunk\n",
    "    \n",
    "    args_list = []  # List to hold arguments for processing\n",
    "    for idx, row in df.iterrows():  # Iterate over each row in the DataFrame\n",
    "        # Construct the image path based on the dataset type\n",
    "        image_path = os.path.join(images_dir, f\"{row['image_id']}.tif\") if dataset_type == 'test' else row['image_path']\n",
    "        label = None if dataset_type == 'test' else row['label']  # Get label only for training dataset\n",
    "        args_list.append((image_path, label, idx, num_patches_per_image))  # Append arguments for processing\n",
    "    \n",
    "    # Use multiprocessing to process images in parallel\n",
    "    with Pool(processes=os.cpu_count()) as pool:\n",
    "        for patches, label in pool.imap(preprocess_image, args_list):  # Process each image\n",
    "            if patches is not None:  # If valid patches are returned\n",
    "                all_images.append(patches)  # Add patches to the image list\n",
    "                if dataset_type != 'test':  # Append label only for training dataset\n",
    "                    all_labels.append(label)\n",
    "                \n",
    "                total_samples += 1  # Increment sample counter\n",
    "                \n",
    "                # Save the chunk if the limit is reached\n",
    "                if total_samples >= chunk_size:\n",
    "                    if dataset_type != 'test':\n",
    "                        save_chunk(np.array(all_images), np.array(all_labels), dataset_type, chunk_index)  # Save training chunk\n",
    "                    else:\n",
    "                        save_test_chunk(np.array(all_images), chunk_index)  # Save test chunk\n",
    "                    chunk_index += 1  # Increment chunk index\n",
    "                    all_images = []  # Reset images list\n",
    "                    all_labels = []  # Reset labels list\n",
    "                    total_samples = 0  # Reset sample counter\n",
    "    \n",
    "    # Save any remaining samples after exiting the loop\n",
    "    if total_samples > 0:\n",
    "        if dataset_type != 'test':\n",
    "            save_chunk(np.array(all_images), np.array(all_labels), dataset_type, chunk_index)  # Save remaining training chunk\n",
    "        else:\n",
    "            save_test_chunk(np.array(all_images), chunk_index)  # Save remaining test chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training and validation chunks\n",
    "def save_chunk(images, labels, dataset_type, chunk_index):\n",
    "    # Save images and labels as .npy files\n",
    "    np.save(f'X_{dataset_type}_chunk_{chunk_index}.npy', images)\n",
    "    np.save(f'y_{dataset_type}_chunk_{chunk_index}.npy', labels)\n",
    "    print(f'Saved {len(images)} samples in X_{dataset_type}_chunk_{chunk_index}.npy and y_{dataset_type}_chunk_{chunk_index}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test dataset chunks\n",
    "def save_test_chunk(images, chunk_index):\n",
    "    # Save test images as .npy file\n",
    "    np.save(f'X_test_chunk_{chunk_index}.npy', images)\n",
    "    print(f'Saved {len(images)} samples in X_test_chunk_{chunk_index}.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(5) Implementing Functions and Generating Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training CSV file containing image metadata\n",
    "train_csv_path = '/kaggle/input/mayo-clinic-strip-ai/train.csv'\n",
    "df_train = pd.read_csv(train_csv_path)  # Read the CSV into a DataFrame\n",
    "\n",
    "# Define the directory containing training images\n",
    "train_images_dir = '/kaggle/input/mayo-clinic-strip-ai/train'\n",
    "\n",
    "# Create the full image paths by appending the directory to the image IDs\n",
    "df_train['image_path'] = df_train['image_id'].apply(lambda x: os.path.join(train_images_dir, f\"{x}.tif\"))\n",
    "\n",
    "# Rename the target column to label for clarity\n",
    "df_train.rename(columns={'target': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stratified K-Folds to maintain label distribution across folds\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(df_train, df_train['label'])):\n",
    "    print(f'Processing fold {fold + 1}')  # Indicate which fold is being processed\n",
    "    \n",
    "    # Split the DataFrame into training and validation sets for the current fold\n",
    "    df_train_fold = df_train.iloc[train_idx]\n",
    "    df_val_fold = df_train.iloc[val_idx]\n",
    "    \n",
    "    # Create and save training dataset chunks for the current fold\n",
    "    create_and_save_dataset_in_chunks(df_train_fold, dataset_type=f'train_fold{fold}', num_patches_per_image=15, chunk_size=5000)\n",
    "    \n",
    "    # Create and save validation dataset chunks for the current fold\n",
    "    create_and_save_dataset_in_chunks(df_val_fold, dataset_type=f'val_fold{fold}', num_patches_per_image=15, chunk_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test CSV file for the test dataset\n",
    "test_csv_path = '/kaggle/input/mayo-clinic-strip-ai/test.csv'\n",
    "df_test = pd.read_csv(test_csv_path)  # Read the test CSV into a DataFrame\n",
    "\n",
    "# Create and save dataset chunks for the test dataset\n",
    "create_and_save_dataset_in_chunks(df_test, dataset_type='test', num_patches_per_image=15, chunk_size=5000)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
